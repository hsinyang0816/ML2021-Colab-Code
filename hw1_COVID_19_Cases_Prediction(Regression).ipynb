{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1_COVID-19_Cases_Prediction(Regression).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsinyang0816/ML2021-Colab-Code/blob/master/hw1_COVID_19_Cases_Prediction(Regression).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0_QVkxCrX3"
      },
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeZnPAiwDRWG"
      },
      "source": [
        "Author: Heng-Jui Chang\n",
        "\n",
        "Slides: https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.pdf  \n",
        "Video: TBA\n",
        "\n",
        "Objectives:\n",
        "* Solve a regression problem with deep neural networks (DNN).\n",
        "* Understand basic DNN training tips.\n",
        "* Get familiar with PyTorch.\n",
        "\n",
        "If any questions, please contact the TAs via TA hours, NTU COOL, or email.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx3x1nDkG-Uy"
      },
      "source": [
        "# **Download Data**\n",
        "\n",
        "\n",
        "If the Google drive links are dead, you can download data from [kaggle](https://www.kaggle.com/c/ml2021spring-hw1/data), and upload data manually to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMj55YDKG6ch",
        "outputId": "5f5a7a05-72f7-4da0-e1f6-ea1f9ebdef18"
      },
      "source": [
        "tr_path = 'covid.train.csv'  # path to training data\n",
        "tt_path = 'covid.test.csv'   # path to testing data\n",
        "\n",
        "!gdown --id '19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF' --output covid.train.csv\n",
        "!gdown --id '1CE240jLm2npU-tdz81-oVKEF3T2yfT1O' --output covid.test.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19CCyCgJrUxtvgZF53vnctJiOJ23T5mqF\n",
            "To: /content/covid.train.csv\n",
            "100% 2.00M/2.00M [00:00<00:00, 31.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CE240jLm2npU-tdz81-oVKEF3T2yfT1O\n",
            "To: /content/covid.test.csv\n",
            "100% 651k/651k [00:00<00:00, 10.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS_4-77xHk44"
      },
      "source": [
        "# **Import Some Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-onQd4JNA5H"
      },
      "source": [
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# For data preprocess\n",
        "import numpy as np\n",
        "import csv\n",
        "import os\n",
        "\n",
        "# For plotting\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "myseed = 42069  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtE3b6JEH7rw"
      },
      "source": [
        "# **Some Utilities**\n",
        "\n",
        "You do not need to modify this part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWMT3uf1NGQp"
      },
      "source": [
        "def get_device():\n",
        "    ''' Get device (if GPU is available, use GPU) '''\n",
        "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "def plot_learning_curve(loss_record, title=''):\n",
        "    ''' Plot learning curve of your DNN (train & dev loss) '''\n",
        "    total_steps = len(loss_record['train'])\n",
        "    x_1 = range(total_steps)\n",
        "    x_2 = x_1[::len(loss_record['train']) // len(loss_record['dev'])]\n",
        "    figure(figsize=(6, 4))\n",
        "    plt.plot(x_1, loss_record['train'], c='tab:red', label='train')\n",
        "    plt.plot(x_2, loss_record['dev'], c='tab:cyan', label='dev')\n",
        "    plt.ylim(0.0, 5.)\n",
        "    plt.xlabel('Training steps')\n",
        "    plt.ylabel('MSE loss')\n",
        "    plt.title('Learning curve of {}'.format(title))\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    print(loss_record['train'][-1])\n",
        "    print(loss_record['dev'][-1])\n",
        "\n",
        "\n",
        "def plot_pred(dv_set, model, device, lim=35., preds=None, targets=None):\n",
        "    ''' Plot prediction of your DNN '''\n",
        "    if preds is None or targets is None:\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        for x, y in dv_set:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            with torch.no_grad():\n",
        "                pred = model(x)\n",
        "                preds.append(pred.detach().cpu())\n",
        "                targets.append(y.detach().cpu())\n",
        "        preds = torch.cat(preds, dim=0).numpy()\n",
        "        targets = torch.cat(targets, dim=0).numpy()\n",
        "\n",
        "    figure(figsize=(5, 5))\n",
        "    plt.scatter(targets, preds, c='r', alpha=0.5)\n",
        "    plt.plot([-0.2, lim], [-0.2, lim], c='b')\n",
        "    plt.xlim(-0.2, lim)\n",
        "    plt.ylim(-0.2, lim)\n",
        "    plt.xlabel('ground truth value')\n",
        "    plt.ylabel('predicted value')\n",
        "    plt.title('Ground Truth v.s. Prediction')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39U_XFX6KOoj"
      },
      "source": [
        "# **Preprocess**\n",
        "\n",
        "We have three kinds of datasets:\n",
        "* `train`: for training\n",
        "* `dev`: for validation\n",
        "* `test`: for testing (w/o target value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-MdwpLL7Dt"
      },
      "source": [
        "## **Dataset**\n",
        "\n",
        "The `COVID19Dataset` below does:\n",
        "* read `.csv` files\n",
        "* extract features\n",
        "* split `covid.train.csv` into train/dev sets\n",
        "* normalize features\n",
        "\n",
        "Finishing `TODO` below might make you pass medium baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zlpIp9ANJRU"
      },
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "    ''' Dataset for loading and preprocessing the COVID19 dataset '''\n",
        "    def __init__(self,\n",
        "                 path,\n",
        "                 mode='train',\n",
        "                 target_only=False):\n",
        "        self.mode = mode\n",
        "\n",
        "        # Read data into numpy arrays\n",
        "        with open(path, 'r') as fp:\n",
        "            data = list(csv.reader(fp))\n",
        "            data = np.array(data[1:])[:, 1:].astype(float)\n",
        "        \n",
        "        if not target_only:\n",
        "            feats = list(range(93))\n",
        "        else:\n",
        "            # TODO: Using 40 states & 2 tested_positive features (indices = 57 & 75)\n",
        "            #feats = list(range(40)) + [42, 43, 57, 60, 61, 75, 78, 79]\n",
        "            feats = list(range(40)) + [40, 41, 42, 43, 57, 58, 59, 60, 61, 75, 76, 77, 78, 79]\n",
        "            #feats = [40, 41, 42, 43, 57, 58, 59, 60, 61, 75, 76, 77, 78, 79]\n",
        "            pass\n",
        "\n",
        "        if mode == 'test':\n",
        "            # Testing data\n",
        "            # data: 893 x 93 (40 states + day 1 (18) + day 2 (18) + day 3 (17))\n",
        "            data = data[:, feats]\n",
        "            self.data = torch.FloatTensor(data)\n",
        "        else:\n",
        "            # Training data (train/dev sets)\n",
        "            # data: 2700 x 94 (40 states + day 1 (18) + day 2 (18) + day 3 (18))\n",
        "            target = data[:, -1]\n",
        "            data = data[:, feats]\n",
        "            \n",
        "            # Splitting training data into train & dev sets\n",
        "            if mode == 'train':\n",
        "                indices = [i for i in range(len(data)) if i % 10 != 1]\n",
        "            elif mode == 'dev':\n",
        "                indices = [i for i in range(len(data)) if i % 10 == 1]\n",
        "            \n",
        "            # Convert data into PyTorch tensors\n",
        "            self.data = torch.FloatTensor(data[indices])\n",
        "            self.target = torch.FloatTensor(target[indices])\n",
        "\n",
        "        # Normalize features (you may remove this part to see what will happen)\n",
        "        #self.data[:, :] = \\\n",
        "        #    (self.data[:, :] - self.data[:, :].mean(dim=0, keepdim=True)) \\\n",
        "        #    / self.data[:, :].std(dim=0, keepdim=True)\n",
        "        #self.data[:, 40:] = \\\n",
        "        #    (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
        "        #    / self.data[:, 40:].std(dim=0, keepdim=True)\n",
        "\n",
        "        self.dim = self.data.shape[1]\n",
        "\n",
        "        print('Finished reading the {} set of COVID19 Dataset ({} samples found, each dim = {})'\n",
        "              .format(mode, len(self.data), self.dim))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Returns one sample at a time\n",
        "        if self.mode in ['train', 'dev']:\n",
        "            # For training\n",
        "            return self.data[index], self.target[index]\n",
        "        else:\n",
        "            # For testing (no target)\n",
        "            return self.data[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Returns the size of the dataset\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlhTlkE7MDo3"
      },
      "source": [
        "## **DataLoader**\n",
        "\n",
        "A `DataLoader` loads data from a given `Dataset` into batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlhLk5t6MBX3"
      },
      "source": [
        "def prep_dataloader(path, mode, batch_size, n_jobs=0, target_only=False):\n",
        "    ''' Generates a dataset, then is put into a dataloader. '''\n",
        "    dataset = COVID19Dataset(path, mode=mode, target_only=target_only)  # Construct dataset\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size,\n",
        "        shuffle=(mode == 'train'), drop_last=False,\n",
        "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
        "    return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGuycwR0MeQB"
      },
      "source": [
        "# **Deep Neural Network**\n",
        "\n",
        "`NeuralNet` is an `nn.Module` designed for regression.\n",
        "The DNN consists of 2 fully-connected layers with ReLU activation.\n",
        "This module also included a function `cal_loss` for calculating loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49-uXYovOAI0"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    ''' A simple fully-connected deep neural network '''\n",
        "    def __init__(self, input_dim):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Define your neural network here\n",
        "        # TODO: How to modify this model to achieve better performance?\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, input_dim),\n",
        "            #nn.ReLU(),\n",
        "            nn.Linear(input_dim, 1)\n",
        "        )\n",
        "\n",
        "        # Mean squared error loss\n",
        "        self.criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "    def forward(self, x):\n",
        "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
        "        return self.net(x).squeeze(1)\n",
        "\n",
        "    def cal_loss(self, pred, target):\n",
        "        ''' Calculate loss '''\n",
        "        # TODO: you may implement L2 regularization here\n",
        "        return torch.sqrt(self.criterion(pred, target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvFWVjZ5Nvga"
      },
      "source": [
        "# **Train/Dev/Test**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAM8QecJOyqn"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOqcmYzMO7jB"
      },
      "source": [
        "def train(tr_set, dv_set, model, config, device):\n",
        "    ''' DNN training '''\n",
        "\n",
        "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
        "\n",
        "    # Setup optimizer\n",
        "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
        "        model.parameters(), **config['optim_hparas'])\n",
        "\n",
        "    min_mse = 1000.\n",
        "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
        "    early_stop_cnt = 0\n",
        "    epoch = 0\n",
        "    while epoch < n_epochs:\n",
        "        model.train()                           # set model to training mode\n",
        "        for x, y in tr_set:                     # iterate through the dataloader\n",
        "            optimizer.zero_grad()               # set gradient to zero\n",
        "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
        "            optimizer.step()                    # update model with optimizer\n",
        "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
        "\n",
        "        # After each epoch, test your model on the validation (development) set.\n",
        "        dev_mse = dev(dv_set, model, device)\n",
        "        if dev_mse < min_mse:\n",
        "            # Save model if your model improved\n",
        "            min_mse = dev_mse\n",
        "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
        "                .format(epoch + 1, min_mse))\n",
        "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
        "            early_stop_cnt = 0\n",
        "        else:\n",
        "            early_stop_cnt += 1\n",
        "\n",
        "        epoch += 1\n",
        "        loss_record['dev'].append(dev_mse)\n",
        "        if early_stop_cnt > config['early_stop']:\n",
        "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
        "            break\n",
        "\n",
        "    print('Finished training after {} epochs'.format(epoch))\n",
        "    return min_mse, loss_record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hSd4Bn3O2PL"
      },
      "source": [
        "## **Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrxrD3YsN3U2"
      },
      "source": [
        "def dev(dv_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    total_loss = 0\n",
        "    for x, y in dv_set:                         # iterate through the dataloader\n",
        "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
        "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
        "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
        "\n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0pdrhQAO41L"
      },
      "source": [
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSBMRFlYN5tB"
      },
      "source": [
        "def test(tt_set, model, device):\n",
        "    model.eval()                                # set model to evalutation mode\n",
        "    preds = []\n",
        "    for x in tt_set:                            # iterate through the dataloader\n",
        "        x = x.to(device)                        # move data to device (cpu/cuda)\n",
        "        with torch.no_grad():                   # disable gradient calculation\n",
        "            pred = model(x)                     # forward pass (compute output)\n",
        "            preds.append(pred.detach().cpu())   # collect prediction\n",
        "    preds = torch.cat(preds, dim=0).numpy()     # concatenate all predictions and convert to a numpy array\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvckkF5dvf0j"
      },
      "source": [
        "# **Setup Hyper-parameters**\n",
        "\n",
        "`config` contains hyper-parameters for training and the path to save your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPXpdumwPjE7"
      },
      "source": [
        "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
        "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
        "target_only = True                   # TODO: Using 40 states & 2 tested_positive features\n",
        "\n",
        "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
        "config = {\n",
        "    'n_epochs': 20000,                # maximum number of epochs\n",
        "    'batch_size': 270,               # mini-batch size for dataloader\n",
        "    'optimizer': 'SGD',              # optimization algorithm (optimizer in torch.optim)\n",
        "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
        "        'lr': 0.00008,                 # learning rate of SGD\n",
        "        'momentum': 0.9,              # momentum for SGD\n",
        "        'weight_decay': 0.001\n",
        "    },\n",
        "    'early_stop': 300,               # early stopping epochs (the number epochs since your model's last improvement)\n",
        "    'save_path': 'models/model.pth'  # your model will be saved here\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j1eOV3TOH-j"
      },
      "source": [
        "# **Load data and model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNrYBMmePLKm",
        "outputId": "69801542-77bf-4662-d4fe-7b4a7c1ba94d"
      },
      "source": [
        "tr_set = prep_dataloader(tr_path, 'train', config['batch_size'], target_only=target_only)\n",
        "dv_set = prep_dataloader(tr_path, 'dev', config['batch_size'], target_only=target_only)\n",
        "tt_set = prep_dataloader(tt_path, 'test', config['batch_size'], target_only=target_only)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished reading the train set of COVID19 Dataset (2430 samples found, each dim = 54)\n",
            "Finished reading the dev set of COVID19 Dataset (270 samples found, each dim = 54)\n",
            "Finished reading the test set of COVID19 Dataset (893 samples found, each dim = 54)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHylSirLP9oh"
      },
      "source": [
        "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX2B_zgSOPTJ"
      },
      "source": [
        "# **Start Training!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrEbUxazQAAZ",
        "outputId": "2ea7271a-1996-488a-dba9-6dbd17c7141c"
      },
      "source": [
        "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model (epoch =    1, loss = 4.9557)\n",
            "Saving model (epoch =    3, loss = 4.0184)\n",
            "Saving model (epoch =    4, loss = 3.2886)\n",
            "Saving model (epoch =    5, loss = 3.0313)\n",
            "Saving model (epoch =    6, loss = 2.9135)\n",
            "Saving model (epoch =    7, loss = 2.8050)\n",
            "Saving model (epoch =    8, loss = 2.7021)\n",
            "Saving model (epoch =    9, loss = 2.5927)\n",
            "Saving model (epoch =   10, loss = 2.4864)\n",
            "Saving model (epoch =   11, loss = 2.3754)\n",
            "Saving model (epoch =   12, loss = 2.2670)\n",
            "Saving model (epoch =   13, loss = 2.1567)\n",
            "Saving model (epoch =   14, loss = 2.0476)\n",
            "Saving model (epoch =   15, loss = 1.9425)\n",
            "Saving model (epoch =   16, loss = 1.8383)\n",
            "Saving model (epoch =   17, loss = 1.7322)\n",
            "Saving model (epoch =   18, loss = 1.6343)\n",
            "Saving model (epoch =   19, loss = 1.5432)\n",
            "Saving model (epoch =   20, loss = 1.4598)\n",
            "Saving model (epoch =   21, loss = 1.3995)\n",
            "Saving model (epoch =   22, loss = 1.3324)\n",
            "Saving model (epoch =   23, loss = 1.2778)\n",
            "Saving model (epoch =   24, loss = 1.2449)\n",
            "Saving model (epoch =   25, loss = 1.2176)\n",
            "Saving model (epoch =   26, loss = 1.2031)\n",
            "Saving model (epoch =   27, loss = 1.1920)\n",
            "Saving model (epoch =   28, loss = 1.1850)\n",
            "Saving model (epoch =   29, loss = 1.1816)\n",
            "Saving model (epoch =   30, loss = 1.1790)\n",
            "Saving model (epoch =   33, loss = 1.1745)\n",
            "Saving model (epoch =   34, loss = 1.1738)\n",
            "Saving model (epoch =   37, loss = 1.1707)\n",
            "Saving model (epoch =   40, loss = 1.1683)\n",
            "Saving model (epoch =   41, loss = 1.1679)\n",
            "Saving model (epoch =   42, loss = 1.1667)\n",
            "Saving model (epoch =   46, loss = 1.1651)\n",
            "Saving model (epoch =   48, loss = 1.1605)\n",
            "Saving model (epoch =   49, loss = 1.1602)\n",
            "Saving model (epoch =   51, loss = 1.1588)\n",
            "Saving model (epoch =   53, loss = 1.1558)\n",
            "Saving model (epoch =   54, loss = 1.1551)\n",
            "Saving model (epoch =   55, loss = 1.1541)\n",
            "Saving model (epoch =   58, loss = 1.1535)\n",
            "Saving model (epoch =   59, loss = 1.1528)\n",
            "Saving model (epoch =   60, loss = 1.1520)\n",
            "Saving model (epoch =   61, loss = 1.1491)\n",
            "Saving model (epoch =   64, loss = 1.1490)\n",
            "Saving model (epoch =   66, loss = 1.1489)\n",
            "Saving model (epoch =   70, loss = 1.1438)\n",
            "Saving model (epoch =   72, loss = 1.1411)\n",
            "Saving model (epoch =   74, loss = 1.1410)\n",
            "Saving model (epoch =   75, loss = 1.1383)\n",
            "Saving model (epoch =   78, loss = 1.1360)\n",
            "Saving model (epoch =   81, loss = 1.1339)\n",
            "Saving model (epoch =   84, loss = 1.1319)\n",
            "Saving model (epoch =   86, loss = 1.1311)\n",
            "Saving model (epoch =   90, loss = 1.1284)\n",
            "Saving model (epoch =   91, loss = 1.1273)\n",
            "Saving model (epoch =   92, loss = 1.1269)\n",
            "Saving model (epoch =   93, loss = 1.1260)\n",
            "Saving model (epoch =   95, loss = 1.1253)\n",
            "Saving model (epoch =  100, loss = 1.1246)\n",
            "Saving model (epoch =  102, loss = 1.1212)\n",
            "Saving model (epoch =  107, loss = 1.1179)\n",
            "Saving model (epoch =  109, loss = 1.1178)\n",
            "Saving model (epoch =  111, loss = 1.1158)\n",
            "Saving model (epoch =  112, loss = 1.1158)\n",
            "Saving model (epoch =  114, loss = 1.1139)\n",
            "Saving model (epoch =  118, loss = 1.1119)\n",
            "Saving model (epoch =  120, loss = 1.1111)\n",
            "Saving model (epoch =  121, loss = 1.1106)\n",
            "Saving model (epoch =  124, loss = 1.1089)\n",
            "Saving model (epoch =  127, loss = 1.1074)\n",
            "Saving model (epoch =  128, loss = 1.1073)\n",
            "Saving model (epoch =  131, loss = 1.1056)\n",
            "Saving model (epoch =  137, loss = 1.1029)\n",
            "Saving model (epoch =  138, loss = 1.1028)\n",
            "Saving model (epoch =  139, loss = 1.1024)\n",
            "Saving model (epoch =  144, loss = 1.1002)\n",
            "Saving model (epoch =  145, loss = 1.0996)\n",
            "Saving model (epoch =  146, loss = 1.0995)\n",
            "Saving model (epoch =  147, loss = 1.0989)\n",
            "Saving model (epoch =  148, loss = 1.0984)\n",
            "Saving model (epoch =  153, loss = 1.0966)\n",
            "Saving model (epoch =  156, loss = 1.0957)\n",
            "Saving model (epoch =  160, loss = 1.0951)\n",
            "Saving model (epoch =  161, loss = 1.0939)\n",
            "Saving model (epoch =  162, loss = 1.0937)\n",
            "Saving model (epoch =  166, loss = 1.0929)\n",
            "Saving model (epoch =  171, loss = 1.0906)\n",
            "Saving model (epoch =  174, loss = 1.0899)\n",
            "Saving model (epoch =  177, loss = 1.0891)\n",
            "Saving model (epoch =  182, loss = 1.0882)\n",
            "Saving model (epoch =  185, loss = 1.0871)\n",
            "Saving model (epoch =  186, loss = 1.0863)\n",
            "Saving model (epoch =  195, loss = 1.0860)\n",
            "Saving model (epoch =  196, loss = 1.0836)\n",
            "Saving model (epoch =  198, loss = 1.0831)\n",
            "Saving model (epoch =  201, loss = 1.0824)\n",
            "Saving model (epoch =  204, loss = 1.0818)\n",
            "Saving model (epoch =  206, loss = 1.0815)\n",
            "Saving model (epoch =  208, loss = 1.0808)\n",
            "Saving model (epoch =  215, loss = 1.0795)\n",
            "Saving model (epoch =  227, loss = 1.0782)\n",
            "Saving model (epoch =  233, loss = 1.0765)\n",
            "Saving model (epoch =  234, loss = 1.0762)\n",
            "Saving model (epoch =  237, loss = 1.0756)\n",
            "Saving model (epoch =  251, loss = 1.0746)\n",
            "Saving model (epoch =  254, loss = 1.0735)\n",
            "Saving model (epoch =  256, loss = 1.0733)\n",
            "Saving model (epoch =  263, loss = 1.0730)\n",
            "Saving model (epoch =  264, loss = 1.0724)\n",
            "Saving model (epoch =  268, loss = 1.0716)\n",
            "Saving model (epoch =  272, loss = 1.0712)\n",
            "Saving model (epoch =  275, loss = 1.0709)\n",
            "Saving model (epoch =  285, loss = 1.0701)\n",
            "Saving model (epoch =  296, loss = 1.0701)\n",
            "Saving model (epoch =  298, loss = 1.0692)\n",
            "Saving model (epoch =  302, loss = 1.0685)\n",
            "Saving model (epoch =  304, loss = 1.0685)\n",
            "Saving model (epoch =  310, loss = 1.0681)\n",
            "Saving model (epoch =  316, loss = 1.0675)\n",
            "Saving model (epoch =  320, loss = 1.0674)\n",
            "Saving model (epoch =  332, loss = 1.0672)\n",
            "Saving model (epoch =  334, loss = 1.0666)\n",
            "Saving model (epoch =  344, loss = 1.0662)\n",
            "Saving model (epoch =  346, loss = 1.0660)\n",
            "Saving model (epoch =  349, loss = 1.0657)\n",
            "Saving model (epoch =  355, loss = 1.0656)\n",
            "Saving model (epoch =  363, loss = 1.0652)\n",
            "Saving model (epoch =  373, loss = 1.0648)\n",
            "Saving model (epoch =  384, loss = 1.0647)\n",
            "Saving model (epoch =  393, loss = 1.0646)\n",
            "Saving model (epoch =  394, loss = 1.0642)\n",
            "Saving model (epoch =  401, loss = 1.0641)\n",
            "Saving model (epoch =  417, loss = 1.0637)\n",
            "Saving model (epoch =  424, loss = 1.0636)\n",
            "Saving model (epoch =  428, loss = 1.0636)\n",
            "Saving model (epoch =  429, loss = 1.0635)\n",
            "Saving model (epoch =  441, loss = 1.0632)\n",
            "Saving model (epoch =  448, loss = 1.0631)\n",
            "Saving model (epoch =  452, loss = 1.0630)\n",
            "Saving model (epoch =  463, loss = 1.0629)\n",
            "Saving model (epoch =  492, loss = 1.0625)\n",
            "Saving model (epoch =  494, loss = 1.0625)\n",
            "Saving model (epoch =  512, loss = 1.0624)\n",
            "Saving model (epoch =  513, loss = 1.0622)\n",
            "Saving model (epoch =  532, loss = 1.0621)\n",
            "Saving model (epoch =  546, loss = 1.0619)\n",
            "Saving model (epoch =  550, loss = 1.0618)\n",
            "Saving model (epoch =  556, loss = 1.0618)\n",
            "Saving model (epoch =  563, loss = 1.0616)\n",
            "Saving model (epoch =  566, loss = 1.0615)\n",
            "Saving model (epoch =  587, loss = 1.0614)\n",
            "Saving model (epoch =  605, loss = 1.0614)\n",
            "Saving model (epoch =  633, loss = 1.0610)\n",
            "Saving model (epoch =  647, loss = 1.0609)\n",
            "Saving model (epoch =  658, loss = 1.0609)\n",
            "Saving model (epoch =  701, loss = 1.0606)\n",
            "Saving model (epoch =  715, loss = 1.0605)\n",
            "Saving model (epoch =  719, loss = 1.0605)\n",
            "Saving model (epoch =  747, loss = 1.0605)\n",
            "Saving model (epoch =  759, loss = 1.0604)\n",
            "Saving model (epoch =  778, loss = 1.0604)\n",
            "Saving model (epoch =  811, loss = 1.0603)\n",
            "Saving model (epoch =  814, loss = 1.0601)\n",
            "Saving model (epoch =  831, loss = 1.0599)\n",
            "Saving model (epoch =  832, loss = 1.0599)\n",
            "Saving model (epoch =  842, loss = 1.0599)\n",
            "Saving model (epoch =  854, loss = 1.0597)\n",
            "Saving model (epoch =  910, loss = 1.0596)\n",
            "Saving model (epoch =  915, loss = 1.0594)\n",
            "Saving model (epoch =  932, loss = 1.0594)\n",
            "Saving model (epoch =  965, loss = 1.0593)\n",
            "Saving model (epoch =  968, loss = 1.0592)\n",
            "Saving model (epoch =  988, loss = 1.0591)\n",
            "Saving model (epoch = 1009, loss = 1.0590)\n",
            "Saving model (epoch = 1021, loss = 1.0590)\n",
            "Saving model (epoch = 1033, loss = 1.0589)\n",
            "Saving model (epoch = 1066, loss = 1.0588)\n",
            "Saving model (epoch = 1074, loss = 1.0587)\n",
            "Saving model (epoch = 1101, loss = 1.0587)\n",
            "Saving model (epoch = 1113, loss = 1.0587)\n",
            "Saving model (epoch = 1135, loss = 1.0587)\n",
            "Saving model (epoch = 1158, loss = 1.0584)\n",
            "Saving model (epoch = 1213, loss = 1.0583)\n",
            "Saving model (epoch = 1238, loss = 1.0582)\n",
            "Saving model (epoch = 1266, loss = 1.0581)\n",
            "Saving model (epoch = 1267, loss = 1.0580)\n",
            "Saving model (epoch = 1275, loss = 1.0580)\n",
            "Saving model (epoch = 1285, loss = 1.0580)\n",
            "Saving model (epoch = 1302, loss = 1.0579)\n",
            "Saving model (epoch = 1326, loss = 1.0579)\n",
            "Saving model (epoch = 1332, loss = 1.0578)\n",
            "Saving model (epoch = 1405, loss = 1.0577)\n",
            "Saving model (epoch = 1408, loss = 1.0577)\n",
            "Saving model (epoch = 1410, loss = 1.0577)\n",
            "Saving model (epoch = 1418, loss = 1.0576)\n",
            "Saving model (epoch = 1436, loss = 1.0575)\n",
            "Saving model (epoch = 1484, loss = 1.0573)\n",
            "Saving model (epoch = 1541, loss = 1.0572)\n",
            "Saving model (epoch = 1571, loss = 1.0572)\n",
            "Saving model (epoch = 1592, loss = 1.0571)\n",
            "Saving model (epoch = 1608, loss = 1.0570)\n",
            "Saving model (epoch = 1644, loss = 1.0569)\n",
            "Saving model (epoch = 1651, loss = 1.0569)\n",
            "Saving model (epoch = 1659, loss = 1.0568)\n",
            "Saving model (epoch = 1663, loss = 1.0568)\n",
            "Saving model (epoch = 1691, loss = 1.0567)\n",
            "Saving model (epoch = 1715, loss = 1.0566)\n",
            "Saving model (epoch = 1743, loss = 1.0566)\n",
            "Saving model (epoch = 1749, loss = 1.0565)\n",
            "Saving model (epoch = 1797, loss = 1.0564)\n",
            "Saving model (epoch = 1802, loss = 1.0563)\n",
            "Saving model (epoch = 1819, loss = 1.0563)\n",
            "Saving model (epoch = 1830, loss = 1.0562)\n",
            "Saving model (epoch = 1891, loss = 1.0561)\n",
            "Saving model (epoch = 1912, loss = 1.0561)\n",
            "Saving model (epoch = 1928, loss = 1.0560)\n",
            "Saving model (epoch = 1935, loss = 1.0560)\n",
            "Saving model (epoch = 1951, loss = 1.0559)\n",
            "Saving model (epoch = 2010, loss = 1.0558)\n",
            "Saving model (epoch = 2066, loss = 1.0557)\n",
            "Saving model (epoch = 2113, loss = 1.0556)\n",
            "Saving model (epoch = 2141, loss = 1.0556)\n",
            "Saving model (epoch = 2156, loss = 1.0555)\n",
            "Saving model (epoch = 2159, loss = 1.0554)\n",
            "Saving model (epoch = 2195, loss = 1.0554)\n",
            "Saving model (epoch = 2198, loss = 1.0552)\n",
            "Saving model (epoch = 2272, loss = 1.0552)\n",
            "Saving model (epoch = 2280, loss = 1.0552)\n",
            "Saving model (epoch = 2316, loss = 1.0552)\n",
            "Saving model (epoch = 2324, loss = 1.0551)\n",
            "Saving model (epoch = 2354, loss = 1.0550)\n",
            "Saving model (epoch = 2368, loss = 1.0550)\n",
            "Saving model (epoch = 2403, loss = 1.0549)\n",
            "Saving model (epoch = 2407, loss = 1.0548)\n",
            "Saving model (epoch = 2445, loss = 1.0548)\n",
            "Saving model (epoch = 2472, loss = 1.0548)\n",
            "Saving model (epoch = 2495, loss = 1.0547)\n",
            "Saving model (epoch = 2503, loss = 1.0546)\n",
            "Saving model (epoch = 2535, loss = 1.0546)\n",
            "Saving model (epoch = 2543, loss = 1.0546)\n",
            "Saving model (epoch = 2548, loss = 1.0545)\n",
            "Saving model (epoch = 2550, loss = 1.0545)\n",
            "Saving model (epoch = 2569, loss = 1.0544)\n",
            "Saving model (epoch = 2602, loss = 1.0544)\n",
            "Saving model (epoch = 2619, loss = 1.0544)\n",
            "Saving model (epoch = 2644, loss = 1.0544)\n",
            "Saving model (epoch = 2664, loss = 1.0543)\n",
            "Saving model (epoch = 2684, loss = 1.0543)\n",
            "Saving model (epoch = 2697, loss = 1.0542)\n",
            "Saving model (epoch = 2734, loss = 1.0542)\n",
            "Saving model (epoch = 2737, loss = 1.0542)\n",
            "Saving model (epoch = 2740, loss = 1.0541)\n",
            "Saving model (epoch = 2758, loss = 1.0541)\n",
            "Saving model (epoch = 2762, loss = 1.0540)\n",
            "Saving model (epoch = 2786, loss = 1.0539)\n",
            "Saving model (epoch = 2792, loss = 1.0539)\n",
            "Saving model (epoch = 2830, loss = 1.0539)\n",
            "Saving model (epoch = 2872, loss = 1.0537)\n",
            "Saving model (epoch = 2906, loss = 1.0537)\n",
            "Saving model (epoch = 2949, loss = 1.0536)\n",
            "Saving model (epoch = 2965, loss = 1.0535)\n",
            "Saving model (epoch = 2986, loss = 1.0535)\n",
            "Saving model (epoch = 3007, loss = 1.0534)\n",
            "Saving model (epoch = 3044, loss = 1.0534)\n",
            "Saving model (epoch = 3049, loss = 1.0533)\n",
            "Saving model (epoch = 3081, loss = 1.0533)\n",
            "Saving model (epoch = 3127, loss = 1.0532)\n",
            "Saving model (epoch = 3141, loss = 1.0531)\n",
            "Saving model (epoch = 3234, loss = 1.0531)\n",
            "Saving model (epoch = 3241, loss = 1.0530)\n",
            "Saving model (epoch = 3244, loss = 1.0530)\n",
            "Saving model (epoch = 3272, loss = 1.0529)\n",
            "Saving model (epoch = 3294, loss = 1.0527)\n",
            "Saving model (epoch = 3361, loss = 1.0527)\n",
            "Saving model (epoch = 3416, loss = 1.0527)\n",
            "Saving model (epoch = 3438, loss = 1.0526)\n",
            "Saving model (epoch = 3462, loss = 1.0526)\n",
            "Saving model (epoch = 3471, loss = 1.0525)\n",
            "Saving model (epoch = 3534, loss = 1.0523)\n",
            "Saving model (epoch = 3590, loss = 1.0522)\n",
            "Saving model (epoch = 3646, loss = 1.0522)\n",
            "Saving model (epoch = 3683, loss = 1.0522)\n",
            "Saving model (epoch = 3686, loss = 1.0521)\n",
            "Saving model (epoch = 3726, loss = 1.0520)\n",
            "Saving model (epoch = 3740, loss = 1.0519)\n",
            "Saving model (epoch = 3751, loss = 1.0519)\n",
            "Saving model (epoch = 3787, loss = 1.0519)\n",
            "Saving model (epoch = 3795, loss = 1.0518)\n",
            "Saving model (epoch = 3810, loss = 1.0518)\n",
            "Saving model (epoch = 3812, loss = 1.0518)\n",
            "Saving model (epoch = 3828, loss = 1.0518)\n",
            "Saving model (epoch = 3856, loss = 1.0517)\n",
            "Saving model (epoch = 3889, loss = 1.0516)\n",
            "Saving model (epoch = 3915, loss = 1.0516)\n",
            "Saving model (epoch = 3968, loss = 1.0515)\n",
            "Saving model (epoch = 4005, loss = 1.0514)\n",
            "Saving model (epoch = 4019, loss = 1.0514)\n",
            "Saving model (epoch = 4029, loss = 1.0513)\n",
            "Saving model (epoch = 4103, loss = 1.0513)\n",
            "Saving model (epoch = 4114, loss = 1.0513)\n",
            "Saving model (epoch = 4116, loss = 1.0513)\n",
            "Saving model (epoch = 4133, loss = 1.0512)\n",
            "Saving model (epoch = 4137, loss = 1.0512)\n",
            "Saving model (epoch = 4150, loss = 1.0512)\n",
            "Saving model (epoch = 4179, loss = 1.0512)\n",
            "Saving model (epoch = 4224, loss = 1.0511)\n",
            "Saving model (epoch = 4228, loss = 1.0510)\n",
            "Saving model (epoch = 4277, loss = 1.0510)\n",
            "Saving model (epoch = 4305, loss = 1.0509)\n",
            "Saving model (epoch = 4327, loss = 1.0509)\n",
            "Saving model (epoch = 4358, loss = 1.0508)\n",
            "Saving model (epoch = 4399, loss = 1.0507)\n",
            "Saving model (epoch = 4410, loss = 1.0507)\n",
            "Saving model (epoch = 4435, loss = 1.0507)\n",
            "Saving model (epoch = 4448, loss = 1.0506)\n",
            "Saving model (epoch = 4470, loss = 1.0506)\n",
            "Saving model (epoch = 4504, loss = 1.0505)\n",
            "Saving model (epoch = 4519, loss = 1.0505)\n",
            "Saving model (epoch = 4539, loss = 1.0504)\n",
            "Saving model (epoch = 4592, loss = 1.0503)\n",
            "Saving model (epoch = 4593, loss = 1.0501)\n",
            "Saving model (epoch = 4741, loss = 1.0500)\n",
            "Saving model (epoch = 4816, loss = 1.0500)\n",
            "Saving model (epoch = 4831, loss = 1.0500)\n",
            "Saving model (epoch = 4851, loss = 1.0498)\n",
            "Saving model (epoch = 4908, loss = 1.0498)\n",
            "Saving model (epoch = 4928, loss = 1.0497)\n",
            "Saving model (epoch = 5045, loss = 1.0497)\n",
            "Saving model (epoch = 5052, loss = 1.0496)\n",
            "Saving model (epoch = 5072, loss = 1.0496)\n",
            "Saving model (epoch = 5089, loss = 1.0495)\n",
            "Saving model (epoch = 5097, loss = 1.0494)\n",
            "Saving model (epoch = 5176, loss = 1.0493)\n",
            "Saving model (epoch = 5180, loss = 1.0493)\n",
            "Saving model (epoch = 5184, loss = 1.0493)\n",
            "Saving model (epoch = 5250, loss = 1.0492)\n",
            "Saving model (epoch = 5267, loss = 1.0491)\n",
            "Saving model (epoch = 5283, loss = 1.0491)\n",
            "Saving model (epoch = 5284, loss = 1.0491)\n",
            "Saving model (epoch = 5304, loss = 1.0490)\n",
            "Saving model (epoch = 5351, loss = 1.0490)\n",
            "Saving model (epoch = 5389, loss = 1.0489)\n",
            "Saving model (epoch = 5403, loss = 1.0489)\n",
            "Saving model (epoch = 5426, loss = 1.0489)\n",
            "Saving model (epoch = 5455, loss = 1.0488)\n",
            "Saving model (epoch = 5589, loss = 1.0487)\n",
            "Saving model (epoch = 5594, loss = 1.0487)\n",
            "Saving model (epoch = 5599, loss = 1.0486)\n",
            "Saving model (epoch = 5615, loss = 1.0486)\n",
            "Saving model (epoch = 5625, loss = 1.0485)\n",
            "Saving model (epoch = 5627, loss = 1.0484)\n",
            "Saving model (epoch = 5670, loss = 1.0484)\n",
            "Saving model (epoch = 5718, loss = 1.0484)\n",
            "Saving model (epoch = 5731, loss = 1.0483)\n",
            "Saving model (epoch = 5746, loss = 1.0483)\n",
            "Saving model (epoch = 5754, loss = 1.0482)\n",
            "Saving model (epoch = 5755, loss = 1.0482)\n",
            "Saving model (epoch = 5880, loss = 1.0480)\n",
            "Saving model (epoch = 5921, loss = 1.0480)\n",
            "Saving model (epoch = 6002, loss = 1.0479)\n",
            "Saving model (epoch = 6037, loss = 1.0478)\n",
            "Saving model (epoch = 6068, loss = 1.0478)\n",
            "Saving model (epoch = 6106, loss = 1.0478)\n",
            "Saving model (epoch = 6114, loss = 1.0477)\n",
            "Saving model (epoch = 6193, loss = 1.0476)\n",
            "Saving model (epoch = 6240, loss = 1.0476)\n",
            "Saving model (epoch = 6246, loss = 1.0475)\n",
            "Saving model (epoch = 6296, loss = 1.0475)\n",
            "Saving model (epoch = 6312, loss = 1.0475)\n",
            "Saving model (epoch = 6314, loss = 1.0473)\n",
            "Saving model (epoch = 6401, loss = 1.0473)\n",
            "Saving model (epoch = 6435, loss = 1.0472)\n",
            "Saving model (epoch = 6503, loss = 1.0471)\n",
            "Saving model (epoch = 6515, loss = 1.0470)\n",
            "Saving model (epoch = 6593, loss = 1.0470)\n",
            "Saving model (epoch = 6599, loss = 1.0469)\n",
            "Saving model (epoch = 6659, loss = 1.0469)\n",
            "Saving model (epoch = 6673, loss = 1.0469)\n",
            "Saving model (epoch = 6695, loss = 1.0468)\n",
            "Saving model (epoch = 6733, loss = 1.0467)\n",
            "Saving model (epoch = 6755, loss = 1.0467)\n",
            "Saving model (epoch = 6796, loss = 1.0467)\n",
            "Saving model (epoch = 6829, loss = 1.0466)\n",
            "Saving model (epoch = 6894, loss = 1.0465)\n",
            "Saving model (epoch = 6907, loss = 1.0464)\n",
            "Saving model (epoch = 6937, loss = 1.0464)\n",
            "Saving model (epoch = 6996, loss = 1.0463)\n",
            "Saving model (epoch = 7028, loss = 1.0463)\n",
            "Saving model (epoch = 7057, loss = 1.0463)\n",
            "Saving model (epoch = 7088, loss = 1.0462)\n",
            "Saving model (epoch = 7119, loss = 1.0461)\n",
            "Saving model (epoch = 7196, loss = 1.0460)\n",
            "Saving model (epoch = 7268, loss = 1.0460)\n",
            "Saving model (epoch = 7297, loss = 1.0459)\n",
            "Saving model (epoch = 7351, loss = 1.0459)\n",
            "Saving model (epoch = 7363, loss = 1.0457)\n",
            "Saving model (epoch = 7474, loss = 1.0456)\n",
            "Saving model (epoch = 7517, loss = 1.0455)\n",
            "Saving model (epoch = 7540, loss = 1.0455)\n",
            "Saving model (epoch = 7609, loss = 1.0455)\n",
            "Saving model (epoch = 7675, loss = 1.0454)\n",
            "Saving model (epoch = 7741, loss = 1.0454)\n",
            "Saving model (epoch = 7808, loss = 1.0454)\n",
            "Saving model (epoch = 7810, loss = 1.0452)\n",
            "Saving model (epoch = 7846, loss = 1.0451)\n",
            "Saving model (epoch = 7898, loss = 1.0451)\n",
            "Saving model (epoch = 7964, loss = 1.0450)\n",
            "Saving model (epoch = 7966, loss = 1.0449)\n",
            "Saving model (epoch = 8054, loss = 1.0449)\n",
            "Saving model (epoch = 8121, loss = 1.0448)\n",
            "Saving model (epoch = 8168, loss = 1.0448)\n",
            "Saving model (epoch = 8177, loss = 1.0446)\n",
            "Saving model (epoch = 8259, loss = 1.0445)\n",
            "Saving model (epoch = 8293, loss = 1.0445)\n",
            "Saving model (epoch = 8394, loss = 1.0444)\n",
            "Saving model (epoch = 8452, loss = 1.0443)\n",
            "Saving model (epoch = 8492, loss = 1.0443)\n",
            "Saving model (epoch = 8548, loss = 1.0443)\n",
            "Saving model (epoch = 8578, loss = 1.0442)\n",
            "Saving model (epoch = 8620, loss = 1.0441)\n",
            "Saving model (epoch = 8646, loss = 1.0441)\n",
            "Saving model (epoch = 8656, loss = 1.0441)\n",
            "Saving model (epoch = 8678, loss = 1.0440)\n",
            "Saving model (epoch = 8703, loss = 1.0439)\n",
            "Saving model (epoch = 8872, loss = 1.0439)\n",
            "Saving model (epoch = 8888, loss = 1.0439)\n",
            "Saving model (epoch = 8926, loss = 1.0438)\n",
            "Saving model (epoch = 9046, loss = 1.0437)\n",
            "Saving model (epoch = 9072, loss = 1.0436)\n",
            "Saving model (epoch = 9094, loss = 1.0436)\n",
            "Saving model (epoch = 9106, loss = 1.0435)\n",
            "Saving model (epoch = 9143, loss = 1.0434)\n",
            "Saving model (epoch = 9232, loss = 1.0434)\n",
            "Saving model (epoch = 9234, loss = 1.0434)\n",
            "Saving model (epoch = 9314, loss = 1.0433)\n",
            "Saving model (epoch = 9343, loss = 1.0432)\n",
            "Saving model (epoch = 9438, loss = 1.0432)\n",
            "Saving model (epoch = 9456, loss = 1.0431)\n",
            "Saving model (epoch = 9502, loss = 1.0430)\n",
            "Saving model (epoch = 9591, loss = 1.0430)\n",
            "Saving model (epoch = 9607, loss = 1.0429)\n",
            "Saving model (epoch = 9638, loss = 1.0428)\n",
            "Saving model (epoch = 9695, loss = 1.0427)\n",
            "Saving model (epoch = 9769, loss = 1.0427)\n",
            "Saving model (epoch = 9775, loss = 1.0427)\n",
            "Saving model (epoch = 9833, loss = 1.0427)\n",
            "Saving model (epoch = 9916, loss = 1.0426)\n",
            "Saving model (epoch = 9969, loss = 1.0425)\n",
            "Saving model (epoch = 10018, loss = 1.0424)\n",
            "Saving model (epoch = 10145, loss = 1.0422)\n",
            "Saving model (epoch = 10398, loss = 1.0421)\n",
            "Saving model (epoch = 10423, loss = 1.0421)\n",
            "Saving model (epoch = 10532, loss = 1.0420)\n",
            "Saving model (epoch = 10535, loss = 1.0420)\n",
            "Saving model (epoch = 10555, loss = 1.0419)\n",
            "Saving model (epoch = 10643, loss = 1.0419)\n",
            "Saving model (epoch = 10739, loss = 1.0418)\n",
            "Saving model (epoch = 10749, loss = 1.0417)\n",
            "Saving model (epoch = 10901, loss = 1.0417)\n",
            "Saving model (epoch = 10902, loss = 1.0416)\n",
            "Saving model (epoch = 10922, loss = 1.0416)\n",
            "Saving model (epoch = 10992, loss = 1.0415)\n",
            "Saving model (epoch = 11023, loss = 1.0415)\n",
            "Saving model (epoch = 11069, loss = 1.0415)\n",
            "Saving model (epoch = 11100, loss = 1.0414)\n",
            "Saving model (epoch = 11164, loss = 1.0413)\n",
            "Saving model (epoch = 11181, loss = 1.0413)\n",
            "Saving model (epoch = 11182, loss = 1.0412)\n",
            "Saving model (epoch = 11244, loss = 1.0412)\n",
            "Saving model (epoch = 11396, loss = 1.0412)\n",
            "Saving model (epoch = 11414, loss = 1.0410)\n",
            "Saving model (epoch = 11560, loss = 1.0410)\n",
            "Saving model (epoch = 11601, loss = 1.0410)\n",
            "Saving model (epoch = 11655, loss = 1.0409)\n",
            "Saving model (epoch = 11677, loss = 1.0409)\n",
            "Saving model (epoch = 11695, loss = 1.0408)\n",
            "Saving model (epoch = 11712, loss = 1.0407)\n",
            "Saving model (epoch = 11899, loss = 1.0407)\n",
            "Saving model (epoch = 11988, loss = 1.0406)\n",
            "Saving model (epoch = 12006, loss = 1.0405)\n",
            "Saving model (epoch = 12238, loss = 1.0405)\n",
            "Saving model (epoch = 12376, loss = 1.0405)\n",
            "Saving model (epoch = 12383, loss = 1.0404)\n",
            "Saving model (epoch = 12402, loss = 1.0403)\n",
            "Saving model (epoch = 12414, loss = 1.0402)\n",
            "Saving model (epoch = 12574, loss = 1.0401)\n",
            "Saving model (epoch = 12618, loss = 1.0400)\n",
            "Saving model (epoch = 12826, loss = 1.0399)\n",
            "Saving model (epoch = 12877, loss = 1.0398)\n",
            "Saving model (epoch = 13069, loss = 1.0398)\n",
            "Saving model (epoch = 13080, loss = 1.0398)\n",
            "Saving model (epoch = 13099, loss = 1.0398)\n",
            "Saving model (epoch = 13105, loss = 1.0396)\n",
            "Finished training after 13406 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "hsNO9nnXQBvP",
        "outputId": "8d8fda7c-8d77-4ab8-d2fe-8610707cd0bc"
      },
      "source": [
        "plot_learning_curve(model_loss_record, title='deep model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.8467915654182434\n",
            "1.0397266149520874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "3iZTVn5WQFpX",
        "outputId": "8bb4b923-33a2-453c-c50b-116ccfc912d2"
      },
      "source": [
        "del model\n",
        "model = NeuralNet(tr_set.dataset.dim).to(device)\n",
        "ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
        "model.load_state_dict(ckpt)\n",
        "plot_pred(dv_set, model, device)  # Show prediction on the validation set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQikz3IPiyPf"
      },
      "source": [
        "# **Testing**\n",
        "The predictions of your model on testing set will be stored at `pred.csv`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8cTuQjQQOon",
        "outputId": "8330b3fd-596a-40f8-c0d4-95f83ffd868e"
      },
      "source": [
        "def save_pred(preds, file):\n",
        "    ''' Save predictions to specified file '''\n",
        "    print('Saving results to {}'.format(file))\n",
        "    with open(file, 'w') as fp:\n",
        "        writer = csv.writer(fp)\n",
        "        writer.writerow(['id', 'tested_positive'])\n",
        "        for i, p in enumerate(preds):\n",
        "            writer.writerow([i, p])\n",
        "\n",
        "preds = test(tt_set, model, device)  # predict COVID-19 cases with your model\n",
        "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving results to pred.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfrVxqJanGpE"
      },
      "source": [
        "# **Hints**\n",
        "\n",
        "## **Simple Baseline**\n",
        "* Run sample code\n",
        "\n",
        "## **Medium Baseline**\n",
        "* Feature selection: 40 states + 2 `tested_positive` (`TODO` in dataset)\n",
        "\n",
        "## **Strong Baseline**\n",
        "* Feature selection (what other features are useful?)\n",
        "* DNN architecture (layers? dimension? activation function?)\n",
        "* Training (mini-batch? optimizer? learning rate?)\n",
        "* L2 regularization\n",
        "* There are some mistakes in the sample code, can you find them?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tmCwXgpot3t"
      },
      "source": [
        "# **Reference**\n",
        "This code is completely written by Heng-Jui Chang @ NTUEE.  \n",
        "Copying or reusing this code is required to specify the original author. \n",
        "\n",
        "E.g.  \n",
        "Source: Heng-Jui Chang @ NTUEE (https://github.com/ga642381/ML2021-Spring/blob/main/HW01/HW01.ipynb)\n"
      ]
    }
  ]
}